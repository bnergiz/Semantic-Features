{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Features_3DVision_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juuuuuuuuuu/Semantic-Features/blob/master/Semantic_Features_3DVision_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERvIJ-nkskO",
        "colab_type": "text"
      },
      "source": [
        "Our mapping pipeline is of the following structure:\n",
        "\n",
        "1.   Detection of objects of certain object classes (e.g. traffic sign). Output: object bounding boxes\n",
        "2.   Triangulation of objects. Output: object position relative to pose\n",
        "3.   Creating map of objects. (And refining with filter, BA, etc.) Output: List of objects and their corresponding positions\n",
        "4.   Visualizing map.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1TSOFcEnsjx",
        "colab_type": "text"
      },
      "source": [
        "We start by loading the benchmark dataset. The Cityscapes dataset is used. \n",
        "\n",
        "Scripts for analyzing the dataset can be found here: https://github.com/mcordts/cityscapesScripts\n",
        "\n",
        "How to download the zip files directly: https://towardsdatascience.com/download-city-scapes-dataset-with-script-3061f87b20d7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90OSmAcrn9dC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m pip install cityscapesscripts\n",
        "!sudo apt install python-tk python-qt4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZzfpy_nzOPV",
        "colab_type": "code",
        "outputId": "a84c3dcd-9677-4ae1-8425-871c9ec3fc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!csDownload\n",
        "\n",
        "# Username: ftaubner@ethz.ch\n",
        "# Password: semantic_dudes"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cityscapes username or email address: ftaubner@ethz.ch\n",
            "Cityscapes password: \n",
            "Store credentials unencrypted in '/root/.local/share/cityscapesscripts/credentials.json' [y/N]: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ZU2SJr1Ifg",
        "colab_type": "text"
      },
      "source": [
        "Download image data: \n",
        "\n",
        "*   leftImg8bit_trainvaltest.zip\n",
        "*   camera_trainvaltest.zip\n",
        "*   vehicle_trainvaltest.zip\n",
        "\n",
        "TODO: \n",
        "\n",
        "*   rightImg8bit_trainvaltest.zip (requested)\n",
        "*   disparity_trainvaltest.zip (requested)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1GyIOSzP06",
        "colab_type": "code",
        "outputId": "a2a076bf-4f2a-4db3-af9c-33c9af5b8459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        }
      },
      "source": [
        "# Download zips (run only once!).\n",
        "\n",
        "# Login.\n",
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=ftaubner@ethz.ch&password=semantic_dudes&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "# Get left camera images.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3\n",
        "# Get camera intrinsics. \n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=8\n",
        "# Get vehicle odometry.\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=10"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-10 10:19:32--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-03-10 10:19:32--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html’\n",
            "\n",
            "index.html              [ <=>                ]  41.38K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-10 10:19:34 (385 KB/s) - ‘index.html’ saved [42371]\n",
            "\n",
            "--2020-03-10 10:19:36--  https://www.cityscapes-dataset.com/file-handling/?packageID=3\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11592327197 (11G) [application/octet-stream]\n",
            "Saving to: ‘leftImg8bit_trainvaltest.zip’\n",
            "\n",
            "leftImg8bit_trainva 100%[===================>]  10.80G  35.5MB/s    in 4m 19s  \n",
            "\n",
            "2020-03-10 10:23:55 (42.7 MB/s) - ‘leftImg8bit_trainvaltest.zip’ saved [11592327197/11592327197]\n",
            "\n",
            "--2020-03-10 10:24:00--  https://www.cityscapes-dataset.com/file-handling/?packageID=8\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1947737 (1.9M) [application/octet-stream]\n",
            "Saving to: ‘camera_trainvaltest.zip’\n",
            "\n",
            "camera_trainvaltest 100%[===================>]   1.86M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-10 10:24:00 (12.9 MB/s) - ‘camera_trainvaltest.zip’ saved [1947737/1947737]\n",
            "\n",
            "--2020-03-10 10:24:02--  https://www.cityscapes-dataset.com/file-handling/?packageID=10\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1905760 (1.8M) [application/octet-stream]\n",
            "Saving to: ‘vehicle_trainvaltest.zip’\n",
            "\n",
            "vehicle_trainvaltes 100%[===================>]   1.82M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-10 10:24:02 (12.8 MB/s) - ‘vehicle_trainvaltest.zip’ saved [1905760/1905760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SqJzKpI4Z6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract zips. Only Zurich.\n",
        "\n",
        "!unzip leftImg8bit_trainvaltest.zip 'leftImg8bit/train/zurich/*' -d images\n",
        "\n",
        "!unzip camera_trainvaltest.zip -d camera\n",
        "\n",
        "!unzip vehicle_trainvaltest.zip -d odometry"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwU_f_b7nH-O",
        "colab_type": "text"
      },
      "source": [
        "We start with the detection of objects of interest. Faster R-CNN is used for this task. (Julius)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UEmUojHy0Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbkKU6cny-6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEnImM8jzDVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXh-WMRDzqFe",
        "colab_type": "text"
      },
      "source": [
        "Loading an on COCO pre-trained Faster R-CNN \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNOoJunDzH55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "im = cv2.imread(\"Test.jpeg\")\n",
        "plt.imshow(im)\n",
        "outputs = predictor(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yphk0gIdzvEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualize results\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "plt.imshow(v.get_image()[:, :, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8ZQm5lzz5s",
        "colab_type": "text"
      },
      "source": [
        "Installing Seamless Scene Segmentation from https://github.com/mapillary/seamseg\n",
        "For Seamless Scene Segmentation a pre-trained version on the Mapillary Dataset exists. Dataloaders for Cityscapes seem to exist, too.\n",
        "\n",
        "It is a network for panoptic segmentation basen on Mask-R-CNN. Alternatively the panoptic variant in the detectron2 reopisitory can also be trained on Cityscapes or Mapillary. Dataloaders seem to exist for both Datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq9ofO5zzmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!pip install git+https://github.com/mapillary/seamseg.git\n",
        "!pip install wget\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1ULhd_CZ24L8FnI9lZ2H6Xuf03n6NA_-Y/view'\n",
        "wget.download(url)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}